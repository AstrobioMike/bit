#!/usr/bin/env python

"""
coverage threshold is applied differently for short vs long targets (coded as < 10,000 bases vs >= 10,000 bases)

    "short" ones are based on percent of subject covered by alignment based
        on blast_df["length"] / blast_df["slen"]) * 100 for individual alignments
        that surpass the percent identity threshold

    "long" ones are based on total percent of subject covered by alignment based on
        the merged regions of all alignments that surpass the percent identity threshold
"""


import os
import argparse
import pandas as pd
import sys
import textwrap
import subprocess
from io import StringIO
from Bio import SeqIO
from tqdm import tqdm

parser = argparse.ArgumentParser(description="This script takes a set of target genes or regions to find \
                                 (currently NT only), searches for them in input assemblies (currently just with \
                                 blastn), and returns the general BLAST output table as well as a \
                                 simplified summary table that just reports how many times each target \
                                 was found in each input assembly (if the target was < 10,000 bases), \
                                 or if the target was detected at all (if the target was >= 10,000 bases), based \
                                 on tunable minimum target coverage and percent-identity thresholds. For \
                                 version info, run `bit-version`.",
                                 epilog="Ex. usage: bit-ez-screen -a assembly.fasta -t targets.fasta")

required = parser.add_argument_group('REQUIRED PARAMETERS')
optional = parser.add_argument_group('OPTIONAL PARAMETERS')

required.add_argument("-a", "--assemblies", help = "Assembly files in fasta format", metavar = "<FILE>", required = True,
                      nargs = '+')
required.add_argument("-t", "--targets", help = "Targets you want to search for, e.g. genes/regions, in nucleotide form",
                      metavar = "<FILE>", required = True)

optional.add_argument("-o", "--output-prefix", help = 'Output prefix (default: "ez-screen")', action = "store",
                      metavar = "<STR>", default = "ez-screen")

optional.add_argument("-m", "--min-perc-id",
                      help = 'Minimum percent ID for a hit to be counted as found in output summary table (default: 80)',
                      metavar = "<INT>", action = "store", default = 80, type = float)

optional.add_argument("-M", "--min-perc-cov",
                      help = 'Minimum percent coverage of a target for it to be counted as found \
                              in output summary table (default: 80)',
                      metavar = "<INT>", action = "store", default = 80, type = float)

optional.add_argument("-T", "--transpose-output-tsv", help = 'Set this flag if we want to have the output table have targets as rows rather than columns.', action = "store_true")

optional.add_argument("-f", "--filter-if-not-detected",
                      help = "By default, all targets are included in the output table, even if they weren't detected \
                              in any input assemblies. Add this flag if you'd like to filter them out of the final output table.",
                      action = "store_true")


if len(sys.argv)==1:
    parser.print_help(sys.stderr)
    sys.exit(0)

args = parser.parse_args()

################################################################################

def main():

    assembly_path_dict = preflight()

    run_screen(assembly_path_dict)

    report_finished()

################################################################################

##### global vars #####
blast_results_dir = args.output_prefix + "-blast-results"
long_target_length_cutoff = 10000

##### primary functions #####
def preflight():

    check_inputs(args.assemblies, args.targets)

    if not os.path.exists(blast_results_dir):
        os.makedirs(blast_results_dir)

    # checking if there'd be any duplicates with just basenames (like same filename from different path),
    # and retaining input path info if so
    assembly_basenames = [os.path.splitext(os.path.basename(assembly))[0] for assembly in args.assemblies]
    basename_counts = {basename: assembly_basenames.count(basename) for basename in assembly_basenames}

    if any(count > 1 for count in basename_counts.values()):
        assembly_path_dict = {assembly: assembly for assembly in args.assemblies}
    else:
        assembly_path_dict = {assembly: os.path.splitext(os.path.basename(assembly))[0] for assembly in args.assemblies}

    return assembly_path_dict


def run_screen(assembly_path_dict):

    targets_dict = get_targets()
    summary_df = pd.DataFrame()
    total_assemblies = len(args.assemblies)

    print("")

    for i, assembly in enumerate(tqdm(args.assemblies, total = total_assemblies,
                                      desc = "Processing assemblies", unit = "assembly",
                                      bar_format="{l_bar}{bar} | {n_fmt}/{total_fmt} processed, {remaining} remaining")):

        blast_df = run_blast(assembly)
        filtered_blast_df, long_targets_results_dict = filter_blast_results(blast_df, targets_dict)

        unique_assembly_name = assembly_path_dict[assembly]
        summary_df = update_summary_table(filtered_blast_df, long_targets_results_dict, targets_dict, unique_assembly_name, summary_df)

    if args.filter_if_not_detected:
        summary_df = filter_undetected_targets(summary_df)

    if args.transpose_output_tsv:
        summary_df = summary_df.T
        summary_df.to_csv(args.output_prefix + "-summary-table.tsv", sep = "\t", index_label = "target")
    else:
        summary_df.to_csv(args.output_prefix + "-summary-table.tsv", sep = "\t", index_label = "input-assembly")


def filter_undetected_targets(summary_df):
    """ filters out targets that weren't detected in any input assemblies """

    cols_to_drop = summary_df.columns[
        summary_df.apply(lambda col: set(col.astype(str)) <= {"0", "NOT-DETECTED"})
    ]

    return summary_df.drop(columns=cols_to_drop)


def report_finished():

    report_message("Done!", color = "green")
    print(f"    Summary table written to: {args.output_prefix}-summary-table.tsv")
    print(f"    Full and filtered BLAST results written in subdirectory: {blast_results_dir}/\n")


def check_inputs(assemblies, targets):
    """ checks that input files exist """

    for assembly in assemblies:
        if not os.path.exists(assembly):
            report_failure(f"Specified input assembly file not found: {assembly}")
        if os.path.isdir(assembly):
            report_failure(f"Specified input assembly is a directory, but needs to be a file or files: {assembly}")

    if not os.path.exists(targets):
        report_failure(f"Specified input targets file not found: {targets}")
    if os.path.isdir(assembly):
        report_failure(f"Specified input targets is a directory, but needs to be a file: {assembly}")


def run_blast(assembly, targets = args.targets, output_prefix = args.output_prefix):
    """ runs BLAST to search for targets in assembly """

    blast_command = [
        "blastn",
        "-task", "blastn",
        "-query", assembly,
        "-subject", targets,
        "-outfmt", "6 qseqid qlen sseqid slen qstart qend sstart send length qcovs qcovhsp qcovus pident evalue bitscore",
    ]

    try:
        blast_results = subprocess.check_output(blast_command, stderr = subprocess.STDOUT, text = True)
    except subprocess.CalledProcessError as e:
        report_failure("BLAST failed with the following error:  \n" + e.output)

    blast_results = StringIO(blast_results)

    blast_df = pd.read_csv(blast_results, sep = "\t", header = None, names = [
        "qseqid", "qlen", "sseqid", "slen", "qstart", "qend", "sstart",
        "send", "length", "qcovs", "qcovhsp", "qcovus", "pident", "evalue", "bitscore"
    ])

    assembly_base = os.path.splitext(os.path.basename(assembly))[0]

    # adding percent of subject covered by alignment
    blast_df["perc-subj-cov"] = round((blast_df["length"] / blast_df["slen"]) * 100, 1)

    blast_df.to_csv(f"{blast_results_dir}/{assembly_base}-blast-results.tsv", sep = "\t", index = False)

    return blast_df


def get_targets():
    """ creates a dictionary of the targets based on input fasta headers as keys and lengths as values"""

    targets_dict = {}

    for record in SeqIO.parse(args.targets, "fasta"):
        targets_dict[record.id] = len(record.seq)

    return targets_dict


def filter_blast_results(blast_df, targets_dict, min_perc_id = args.min_perc_id, min_perc_cov = args.min_perc_cov):
    """ Filter BLAST results based on user-specified thresholds """

    # if query is targets and subject is assembly
    # short_targets_df, long_targets_df = blast_df[blast_df["qlen"] < long_target_length_cutoff], blast_df[blast_df["qlen"] >= long_target_length_cutoff]

    # if query is assembly and subject is targets
    short_targets_df, long_targets_df = blast_df[blast_df["slen"] < long_target_length_cutoff], blast_df[blast_df["slen"] >= long_target_length_cutoff]

    filtered_short_blast_df = short_targets_df[(short_targets_df["pident"] >= min_perc_id) & (short_targets_df["perc-subj-cov"] >= min_perc_cov)]

    if not long_targets_df.empty:

        filtered_long_blast_df = long_targets_df[(long_targets_df["pident"] >= min_perc_id)]
        long_targets_results_dict = gen_long_targets_results_dict(filtered_long_blast_df, targets_dict)

    else:
        long_targets_results_dict = None

    return filtered_short_blast_df, long_targets_results_dict


def gen_long_targets_results_dict(filtered_long_blast_df, targets_dict):
    """ remove overlapping alignments and calculate total percent of subject covered by alignment """

    # the sstart and sstop positions aren't necessarily in order from lowest to highest,
    # which is needed for how we merge the covered regions below
    # so here was are making new columns that are the min and max of the two
    filtered_long_blast_df = filtered_long_blast_df.copy() # make a copy to avoid SettingWithCopyWarning
    filtered_long_blast_df["mod_sstart"] = filtered_long_blast_df[["sstart", "send"]].min(axis = 1)
    filtered_long_blast_df["mod_send"] = filtered_long_blast_df[["sstart", "send"]].max(axis = 1)

    long_subject_ids = [key for key, value in targets_dict.items() if value >= long_target_length_cutoff]

    long_targets_detected_dict = {}

    for ID in long_subject_ids:

        sub_df = filtered_long_blast_df[filtered_long_blast_df["sseqid"] == ID]

        if sub_df.empty:
            long_targets_detected_dict[ID] = "NOT-DETECTED"
            continue

        sub_df = sub_df.sort_values(by = ["mod_sstart"])

        merged_regions = []

        for index, row in sub_df.iterrows():

            start, end = row['mod_sstart'], row['mod_send']

            # if this is the first region or no overlap, adding the region
            if not merged_regions or start > merged_regions[-1][1]:
                merged_regions.append([start, end])
            else:
                # otherwise, merging the current region with the previous one
                merged_regions[-1][1] = max(merged_regions[-1][1], end)

        total_subject_bases_covered = sum(end - start + 1 for start, end in merged_regions)

        if total_subject_bases_covered >= args.min_perc_cov * targets_dict[ID] / 100:
            long_targets_detected_dict[ID] = "DETECTED"
        else:
            long_targets_detected_dict[ID] = "NOT-DETECTED"

    return long_targets_detected_dict


def update_summary_table(filtered_short_blast_df, long_targets_detected_dict, targets_dict, unique_assembly_name, summary_df):
    """ Update the summary table with results from the current assembly """

    target_counts = filtered_short_blast_df["sseqid"].value_counts()

    new_row = pd.DataFrame(columns=targets_dict.keys(), index=[unique_assembly_name])

    for target in targets_dict.keys():
        new_row.at[unique_assembly_name, target] = target_counts.get(target, 0)

    if long_targets_detected_dict:
        for col, new_value in long_targets_detected_dict.items():
            new_row.at[unique_assembly_name, col] = new_value

    summary_df = pd.concat([summary_df, new_row])

    return summary_df

################################################################################
##### general utils #####

tty_colors = {
    'green' : '\033[0;32m%s\033[0m',
    'yellow' : '\033[0;33m%s\033[0m',
    'red' : '\033[0;31m%s\033[0m'
}


def color_text(text, color = 'green'):
    if sys.stdout.isatty():
        return tty_colors[color] % text
    else:
        return text


def wprint(text):
    """ print wrapper """

    print(textwrap.fill(text, width = 80, initial_indent = "  ",
          subsequent_indent = "  ", break_on_hyphens = False))


def report_message(message, color = "yellow"):
    print("")
    wprint(color_text(message, color))


def report_failure(message, color = "red"):
    print("")
    wprint(color_text(message, color))
    print("\nExiting for now :(\n")
    sys.exit(1)

################################################################################

if __name__ == "__main__":
    main()
